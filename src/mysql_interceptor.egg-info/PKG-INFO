Metadata-Version: 2.4
Name: mysql-interceptor
Version: 0.1.0
Summary: Intercept MySQL writes and mirror to Kafka with Java-compatible schema.
Author: Your Team
License: MIT
Requires-Python: >=3.9
Description-Content-Type: text/markdown
Provides-Extra: pymysql
Requires-Dist: PyMySQL>=1.1; extra == "pymysql"
Provides-Extra: sqlalchemy
Requires-Dist: SQLAlchemy>=1.4; extra == "sqlalchemy"
Provides-Extra: confluent
Requires-Dist: confluent-kafka>=2.2; extra == "confluent"
Provides-Extra: kafka-python
Requires-Dist: kafka-python>=2.0; extra == "kafka-python"

# mysql-interceptor

Drop-in interception for MySQL writes that mirrors events to Kafka using a Java-compatible JSON schema.

## Enable Kafka via env vars (Java-compatible)

Kafka export is enabled when `INTERCEPTOR_KAFKA_BOOTSTRAP_SERVERS` is set and you don't pass `publisher=...`.

```bash
export INTERCEPTOR_KAFKA_BOOTSTRAP_SERVERS="server1:9092,server2:9092"
export INTERCEPTOR_KAFKA_TOPIC="MYSQL_EVENTS"
export INTERCEPTOR_KAFKA_ACKS="all"
export INTERCEPTOR_KAFKA_RETRIES="3"
export INTERCEPTOR_KAFKA_LINGER_MS="1000"
export INTERCEPTOR_KAFKA_BATCH_SIZE="16384"
export INTERCEPTOR_KAFKA_BUFFER_MEMORY="33554432"
export INTERCEPTOR_KAFKA_ADAPTIVE_PARTITIONING_ENABLED="true"
```

## Output schema

Kafka messages use the same field names as the Java interceptor's `SqlLogMessage`
(see `src/mysql_interceptor/events/models.py`).

Note: `timestamp` is **epoch milliseconds (wall clock)** and represents the statement start time estimate:
`end_ms - (durationNs/1e6)` (Java-compatible).



## iFlags and isolation levels

See `docs/IFLAGS.md`.
## Drop-in options

### PyMySQL

```python
from mysql_interceptor.monkeypatch import patch_pymysql

unpatch = patch_pymysql()
# your code that calls pymysql.connect(...)
unpatch()
```

### SQLAlchemy

```python
from mysql_interceptor.monkeypatch import patch_sqlalchemy

unpatch = patch_sqlalchemy()
# your code that calls sqlalchemy.create_engine(...)
unpatch()
```

## executemany behavior

`executemany(...)` emits **one Kafka record per parameter set**.
Only the **last** record contains `durationNs` and `updateCount` for the whole batch; earlier records set them to null.


## Makefile

From repo root:

- `make up` (starts MySQL+Kafka)
- `make pymysql-test / make alchemysql-test` (unit tests)
- `make pymysql-test / make alchemysql-test-integration` (runs both suites; install deps per `tests/integration/*/requirements.txt`)
- `make down`


### Inspect Kafka output

After running tests, you can print interceptor JSON events from Kafka:

```bash
make inspect-results
```

Optional filters (default topic is `MYSQL_EVENTS`):

```bash
make inspect-results TOPIC=MYSQL_EVENTS
make inspect-results PATTERN='MYSQL_EVENTS_TEST_.*'
```

List topics:

```bash
source tests/integration/pymysql/.venv/bin/activate
python scripts/inspect_kafka.py --bootstrap localhost:9092 --list-topics
```


Note: `make pymysql-test` / `make alchemysql-test` automatically install the library in editable mode into the integration venv.


Note: integration targets run pytest from the repo root so test helpers under `tests/` can be imported.
